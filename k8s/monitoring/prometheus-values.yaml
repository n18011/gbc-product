# kube-prometheus-stack用のHelmチャート値設定
# kind環境向けの最小構成

# 基本設定
nameOverride: "monitoring"
fullnameOverride: "monitoring"

# Prometheusサーバー設定
prometheus:
  prometheusSpec:
    # リソース設定の最適化
    resources:
      requests:
        memory: "1Gi"  # 512Mi から 1Gi に増加
        cpu: "200m"    # 100m から 200m に増加
      limits:
        memory: "2Gi"  # 1Gi から 2Gi に増加
        cpu: "500m"    # 400m から 500m に増加
    # データ保持期間（7日間）
    retention: "7d"
    # 永続ボリューム設定
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: "nfs-storage"
          accessModes: ["ReadWriteMany"]
          resources:
            requests:
              storage: "5Gi"
    # ServiceMonitor設定
    serviceMonitorSelector:
      matchLabels:
        release: monitoring
    # PodMonitor設定
    podMonitorSelector:
      matchLabels:
        release: monitoring
    # 設定ルール
    ruleSelector:
      matchLabels:
        release: monitoring
    # ヘルスチェック待機時間の延長
    readinessProbeInitialDelay: 60  # 追加
    livenessProbeInitialDelay: 120  # 追加
    # スタートアッププローブ設定
    startupProbe:
      failureThreshold: 120    # 120回まで失敗を許容（デフォルト60）
      periodSeconds: 5         # 5秒ごとに確認
      timeoutSeconds: 5        # タイムアウトを5秒に設定
    # 機能制限と最適化
    logLevel: warn             # ログレベルを警告のみに設定
    scrapeInterval: "60s"      # スクレイプ間隔を延長
    evaluationInterval: "60s"  # 評価間隔を延長
    tsdb:
      outOfOrderTimeWindow: 0  # 時系列データベースの時間順序外サンプルウィンドウを無効化
    walCompression: true       # WALの圧縮を有効化してディスク使用量を削減

# Grafana設定
grafana:
  adminPassword: "admin"
  resources:
    requests:
      memory: "512Mi"  # 256Mi から 512Mi に増加
      cpu: "200m"      # 100m から 200m に増加
    limits:
      memory: "1Gi"    # 512Mi から 1Gi に増加
      cpu: "300m"      # 200m から 300m に増加
  # ヘルスチェック待機時間の延長
  readinessProbe:
    initialDelaySeconds: 60  # 追加
  livenessProbe:
    initialDelaySeconds: 120  # 追加
  persistence:
    enabled: true
    storageClassName: "nfs-storage"
    size: "2Gi"
    accessModes: ["ReadWriteMany"]
  service:
    type: ClusterIP
  ingress:
    enabled: true
    hosts:
      - "monitoring.localhost"
    path: "/"
  # デフォルトダッシュボード設定
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'default'
          orgId: 1
          folder: ''
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/default
  # デフォルトのデータソース設定
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          url: http://monitoring-prometheus:9090
          access: proxy
          isDefault: true

# AlertManager設定
alertmanager:
  alertmanagerSpec:
    resources:
      requests:
        memory: "128Mi"  # 64Mi から 128Mi に増加
        cpu: "100m"      # 50m から 100m に増加
      limits:
        memory: "256Mi"  # 128Mi から 256Mi に増加
        cpu: "200m"      # 100m から 200m に増加
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: "nfs-storage"
          accessModes: ["ReadWriteMany"]
          resources:
            requests:
              storage: "1Gi"
    # テスト用の基本構成
    config:
      global:
        resolve_timeout: 5m
      route:
        group_by: ['alertname', 'job']
        group_wait: 30s
        group_interval: 5m
        repeat_interval: 12h
        receiver: 'null'
        routes:
          - match:
              alertname: Watchdog
            receiver: 'null'
      receivers:
        - name: 'null'
      inhibit_rules:
        - source_match:
            severity: 'critical'
          target_match:
            severity: 'warning'
          equal: ['alertname', 'namespace']

# ノードエクスポーター設定
nodeExporter:
  enabled: true
  resources:
    requests:
      memory: "128Mi"  # 64Mi から 128Mi に増加
      cpu: "100m"      # 50m から 100m に増加
    limits:
      memory: "256Mi"  # 128Mi から 256Mi に増加
      cpu: "200m"      # 100m から 200m に増加

# kubeletメトリクス設定
kubelet:
  enabled: true
  serviceMonitor:
    metricRelabelings:
      # kind環境向けに不要なメトリクスを除外
      - action: drop
        regex: kubelet_runtime_operations_latency_microseconds
        sourceLabels: [__name__]

# kubeStateMetrics設定
kubeStateMetrics:
  enabled: true

# prometheusOperator設定
prometheusOperator:
  resources:
    requests:
      memory: "256Mi"  # 128Mi から 256Mi に増加
      cpu: "100m"      # 50m から 100m に増加
    limits:
      memory: "512Mi"  # 256Mi から 512Mi に増加
      cpu: "200m"      # 100m から 200m に増加 